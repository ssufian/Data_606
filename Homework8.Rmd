
title: "Chapter 8 - Introduction to Linear Regression"

author: "Sufian"

output:

  html_document:
  
    df_print: paged
    
  pdf_document:
  
    extra_dependencies:
    
    - geometry
    
    - multicol
    
    - multirow
    
    - xcolor
    


## Rpub links: http://rpubs.com/ssufian/548281

--------------------------------------------------------------------------------

\clearpage


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Nutrition at Starbucks, Part I.** (8.22, p. 326) The scatterplot below shows the relationship between the number of calories and amount of carbohydrates (in grams) Starbucks food menu items contain. Since Starbucks only lists the number of calories on the display items, we are interested in predicting the amount of carbs a menu item has based on its calorie content.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="33%", fig.height=4}
library(openintro)
# load data ---------------------------------------------------------
starbucks <- read.csv("https://github.com/jbryer/DATA606Fall2019/raw/master/course_data/starbucks.csv")
# model calories vs. carbos -----------------------------------------
m_carb_cals <- lm(carb ~ calories, data = starbucks)
# plot calories vs. carbos ------------------------------------------
par(mar = c(3.5, 4, 1, 0.5), las = 1, mgp = c(2.5, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)
plot(carb ~ calories, data = starbucks, 
     pch = 19, col = COL[1,2], 
     xlab = "Calories", ylab = "Carbs (grams)", axes = FALSE)
axis(1)
axis(2, at = seq(20, 80, 20))
box()
abline(m_carb_cals, col = COL[2], lwd = 2)
# plot residuals ----------------------------------------------------
par(mar = c(3.5, 4, 1, 0.5), las = 1, mgp = c(2.5, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)

plot(m_carb_cals$residuals ~ starbucks$calories,
     xlab = "Calories", ylab = "Residuals", 
     col = COL[1,2], pch = 19,
     ylim = c(-30, 30), axes = FALSE)
axis(1)
axis(2, at = seq(-20, 20, 20))
box()
abline(h = 0, lty = 2)
# histogram of residuals --------------------------------------------
par(mar = c(3.5, 2.5, 0.5, 0.5), las = 1, mgp = c(2.5, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)

hist(m_carb_cals$residuals,
     col = COL[1], 
     xlab = "Residuals", ylab = "", main = "", 
     axes = FALSE, xlim = c(-40,40))
axis(1, at = seq(-40, 40, 20))
axis(2)
```

(a) Describe the relationship between number of calories and amount of carbohydrates (in grams) that Starbucks food menu items contain.

--------------------------------------------------------------------------------

\clearpage

ans:

The relationship seems to be linear and exibit positive correlation as evidenced by the 45 degree line

--------------------------------------------------------------------------------

\clearpage

(b) In this scenario, what are the explanatory and response variables?

--------------------------------------------------------------------------------

\clearpage

ans:

The response variable are the carbs while the explanatory (predictor) variables are the calories

--------------------------------------------------------------------------------

\clearpage

(c) Why might we want to fit a regression line to these data?

--------------------------------------------------------------------------------

\clearpage

ans:

The see if there are any linear relationship between the 2 variables and if there are, could use a

simple linear regression formula for predictive purposes

--------------------------------------------------------------------------------

\clearpage

(d) Do these data meet the conditions required for fitting a least squares line?

--------------------------------------------------------------------------------

\clearpage

ans:

Yes, it seems the 2 variables are linear (45 degree line) and the residuals are showing randomess about

the zero line, which means no heterodasticity and the histogram is "quite" normal.

--------------------------------------------------------------------------------

\clearpage



--------------------------------------------------------------------------------

\clearpage

**Body measurements, Part I.** (8.13, p. 316) Researchers studying anthropometry collected body girth measurements and skeletal diameter measurements, as well as age, weight, height and gender for 507 physically active individuals.19 The scatterplot below shows the relationship between height and shoulder girth (over deltoid muscles), both measured in centimeters.

\begin{center}
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="50%", fig.height=4}
# load packages -----------------------------------------------------
library(openintro)
# load data ---------------------------------------------------------
data(bdims)
# plot height vs. shoulder girth ------------------------------------
par(mar = c(3.8, 3.8, 0.5, 0.5), las = 1, mgp = c(2.7, 0.7, 0), 
    cex.lab = 1.25, cex.axis = 1.25)
plot(bdims$hgt ~ bdims$sho.gi, 
     xlab = "Shoulder girth (cm)", ylab = "Height (cm)", 
     pch = 19, col = COL[1,2])
```
\end{center}

(a) Describe the relationship between shoulder girth and height.

--------------------------------------------------------------------------------

\clearpage

ans:

It appears that they are positively related; as shoulder girth increase, so does height

--------------------------------------------------------------------------------

\clearpage


(b) How would the relationship change if shoulder girth was measured in inches while the units of height remained in centimeters?

--------------------------------------------------------------------------------

\clearpage

ans:

The slope would flatten out a bit

--------------------------------------------------------------------------------

\clearpage


                                      
**Body measurements, Part III.** (8.24, p. 326) Exercise above introduces data on shoulder girth and height of a group of individuals. The mean shoulder girth is 107.20 cm with a standard deviation of 10.37 cm. The mean height is 171.14 cm with a standard deviation of 9.41 cm. The correlation between height and shoulder girth is 0.67.

(a) Write the equation of the regression line for predicting height.

--------------------------------------------------------------------------------

\clearpage

```{r}

sx <- 10.37 # std, dev of girth

sy <- 9.41 # std dev of height

corr <- 0.67 #correlation

b1 <- sy/sx*(corr)

b1 # slope

ybar <- 171.4
xbar <- 107.2

b0 <- ybar - b1*xbar

b0

```

--------------------------------------------------------------------------------

\clearpage

ans:

y = 0.6079x + 106.2251


--------------------------------------------------------------------------------

\clearpage


(b) Interpret the slope and the intercept in this context.

--------------------------------------------------------------------------------

\clearpage

ans:

slope =>  for every inch of shoulder girth increase, you get 0.6079 increase in height


--------------------------------------------------------------------------------

\clearpage


(c) Calculate $R^2$ of the regression line for predicting height from shoulder girth, and interpret it in the context of the application.

--------------------------------------------------------------------------------

\clearpage

ans:

0.45%, This means about 45% of the variability in height can be explained by shoulder girth, see below

```{r}
rsquare <- corr*corr

rsquare
```

--------------------------------------------------------------------------------

\clearpage


(d) A randomly selected student from your class has a shoulder girth of 100 cm. Predict the height of this student using the model.

ans:

using the linear equation from (b), y = 0.6079x + 106.2251

The predicted height of student is 167 cm

```{r}
x1 <- 100

y <- b1*x1 + b0

y
```

(e) The student from part (d) is 160 cm tall. Calculate the residual, and explain what this residual means.

```{r}
yact <- 160
res <- yact - y

res
```

--------------------------------------------------------------------------------

\clearpage

ans:

residual is -7.022 or abs residual is 7.022, it is the difference between actual height and predicted 

or in other words, the error between actuals vs. predicted

--------------------------------------------------------------------------------

\clearpage


(f) A one year old has a shoulder girth of 56 cm. Would it be appropriate to use this linear model to predict the height of this child?

--------------------------------------------------------------------------------

\clearpage

ans:

 It would not be appropriate to use this model to calculate the height of a 1 year old since it maybe
 
 outside of the modelâ€™s range.

--------------------------------------------------------------------------------

\clearpage

**Cats, Part I.** (8.26, p. 327) The following regression output is for predicting the heart weight (in g) of cats from their body weight (in kg). The coefficients are estimated using a dataset of 144 domestic cats.

\begin{center}
{
\begin{tabular}{rrrrr}
    \hline
            & Estimate  & Std. Error    & t value   & Pr($>$$|$t$|$) \\ 
    \hline
(Intercept) & -0.357    & 0.692         & -0.515    & 0.607 \\ 
body wt     & 4.034     & 0.250         & 16.119    & 0.000 \\ 
    \hline
\end{tabular} \ \\
$s = 1.452 \qquad R^2 = 64.66\% \qquad R^2_{adj} = 64.41\%$ 
}
\end{center}

\begin{center}
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="50%", fig.height=4}
# load packages -----------------------------------------------------
library(openintro)
library(xtable)
library(MASS)
# load data ---------------------------------------------------------
data(cats)
# model heart weight vs. weight -------------------------------------
m_cats_hwt_bwt <- lm(cats$Hwt ~ cats$Bwt)
# plot heart weight vs. weight --------------------------------------
par(mar = c(3.7, 3.7, 0.5, 0.5), las = 1, mgp = c(2.5, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)
plot(cats$Hwt ~ cats$Bwt, 
     xlab = "Body weight (kg)", ylab = "Heart weight (g)", 
     pch = 19, col = COL[1,2],
     xlim = c(2,4), ylim = c(5, 20.5), axes = FALSE)
axis(1, at = seq(2, 4, 0.5))
axis(2, at = seq(5, 20, 5))
box()
```
\end{center}

(a) Write out the linear model.

--------------------------------------------------------------------------------

\clearpage

ans:

y = 4.034x - 0.357

--------------------------------------------------------------------------------

\clearpage

(b) Interpret the intercept.

--------------------------------------------------------------------------------

\clearpage

ans:

It normally would've indicated the heart weight if body weight was zero.  But in this case, it's a 

matter of "anchoring" the regression line

--------------------------------------------------------------------------------

\clearpage

(c) Interpret the slope.

--------------------------------------------------------------------------------

\clearpage

ans:


slope represent that for a unit increase of body weight, 4.034 unit of heart weight would have

increase accordingly

--------------------------------------------------------------------------------

\clearpage

(d) Interpret $R^2$.

ans:

This means about 64.41% of the variability in height can be explained by body weight


--------------------------------------------------------------------------------

\clearpage



(e) Calculate the correlation coefficient.


--------------------------------------------------------------------------------

\clearpage

ans: r = 80.4%

```{r}

rsquare1 <- 0.6466
corr1 <- sqrt(rsquare1 )

corr1
```


--------------------------------------------------------------------------------

\clearpage

**Rate my professor.** (8.44, p. 340) Many college courses conclude by giving students the opportunity to evaluate the course and the instructor anonymously. However, the use of these student evaluations as an indicator of course quality and teaching effectiveness is often criticized because these measures may reflect the influence of non-teaching related characteristics, such as the physical appearance of the instructor. Researchers at University of Texas, Austin collected data on teaching evaluation score (higher score means better) and standardized beauty score (a score of 0 means average, negative score means below average, and a positive score means above average) for a sample of 463 professors. The scatterplot below shows the relationship between these variables, and also provided is a regression output for predicting teaching evaluation score from beauty score.

\begin{center}
\begin{tabular}{rrrrr}
    \hline
            & Estimate  & Std. Error    & t value   & Pr($>$$|$t$|$) \\ 
  \hline
(Intercept) & 4.010     & 0.0255        & 	157.21  & 0.0000 \\ 
beauty      &  \fbox{\textcolor{white}{{ Cell 1}}}  
                        & 0.0322        & 4.13      & 0.0000\vspace{0.8mm} \\ 
   \hline
\end{tabular}


```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="50%", fig.height=4}
# load packages -----------------------------------------------------
library(openintro)
# load data ---------------------------------------------------------
prof_evals_beauty <- read.csv("https://github.com/jbryer/DATA606Fall2019/raw/master/course_data/prof_evals_beauty.csv")
# rename variables for convenience ----------------------------------
beauty <- prof_evals_beauty$btystdave
eval <- prof_evals_beauty$courseevaluation
# model evaluation scores vs. beauty --------------------------------
m_eval_beauty = lm(eval ~ beauty)
# scatterplot of evaluation scores vs. beauty -----------------------
par(mar = c(3.9, 3.9, 0.5, 0.5), las = 0, mgp = c(2.7, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5, las = 1)
plot(eval ~ beauty, 
     xlab = "Beauty", ylab = "Teaching evaluation", 
     pch = 19, col = COL[1,2], 
     axes = FALSE)
axis(1, at = seq(-1, 2, 1))
axis(2, at = seq(2, 5, 1))
box()
```
\end{center}

(a) Given that the average standardized beauty score is -0.0883 and average teaching evaluation score is 3.9983, calculate the slope. Alternatively, the slope may be computed using just the information provided in the model summary table.

```{r}
avgbeauty <- -0.0883

avgteaching <- 3.9983

intercept <- 4.010

m <- (avgteaching-intercept)/avgbeauty

m
```

--------------------------------------------------------------------------------

\clearpage

ans:  slope = 0.1325, see above

--------------------------------------------------------------------------------

\clearpage

(b) Do these data provide convincing evidence that the slope of the relationship between teaching evaluation and beauty is positive? Explain your reasoning.

--------------------------------------------------------------------------------

\clearpage

ans:

Lets look at the diagnostics from the figures provided below:

-  The residuals vs. independent variable looks scatter, which means that its normal and no

heteorsdasticity

-  the residual plots looks quite normal

-  The Q-Q plots looks good with no extreme kinks, except for the outer edges, so we can safetly say

it does have a normal distribution

-  The residuals vs. order of collection looks scatter as well

Finally, t-stat:

The t-stat is > 0.05 which means that the slope is significant. This all point to the fact that the 

relationship between beauty and teaching is positively correlated

--------------------------------------------------------------------------------

\clearpage


(c) List the conditions required for linear regression and check if each one is satisfied for this model based on the following diagnostic plots.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="50%", fig.height=4}
# residuals plot ----------------------------------------------------
par(mar = c(3.9, 3.9, 0.5, 0.5), las = 0, mgp = c(2.7, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5, las = 1)
plot(m_eval_beauty$residuals ~ beauty, 
     xlab = "Beauty", ylab = "Residuals", 
     pch = 19, col = COL[1,2], 
     ylim = c(-1.82, 1.82), axes = FALSE)
axis(1, at = seq(-1, 2, 1))
axis(2, at = seq(-1, 1, 1))
box()
abline(h = 0, lty = 3)
# residuals histogram -----------------------------------------------
par(mar = c(3.9, 3, 0, 0), cex.lab = 1.5, cex.axis = 1.5)
hist(m_eval_beauty$residuals, 
     xlab = "Residuals", ylab = "", main = "",
     col = COL[1],
     xlim = c(-2,2))
# normal probability plot of residuals ------------------------------
par(mar = c(3.9, 3.9, 0.5, 0.5), mgp = c(2.7, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)
qqnorm(m_eval_beauty$residuals, 
       pch = 19, col = COL[1,2],
       main = "", las = 0)
qqline(m_eval_beauty$residuals, col = COL[1])
# order of residuals ---------------------------------------------===
par(mar = c(3.9, 3.9, 0.5, 0.5), mgp = c(2.7, 0.7, 0), 
    cex.lab = 1.5, cex.axis = 1.5)
plot(m_eval_beauty$residuals, 
     xlab = "Order of data collection", ylab = "Residuals", main = "",
     pch = 19, col = COL[1,2],
     ylim = c(-1.82, 1.82), axes = FALSE)
axis(1)
axis(2, at = seq(-1, 1, 1))
box()
abline(h = 0, lty = 3)
```






